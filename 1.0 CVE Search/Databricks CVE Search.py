# Databricks notebook source
# MAGIC %md
# MAGIC 
# MAGIC ## Databricks CVE Search Dashboard
# MAGIC 
# MAGIC This dashboard is designed to help teams to quickly search a list of CVEs against the Databricks data plane to verify if Databricks is vulnerable to it.

# COMMAND ----------

# MAGIC %md
# MAGIC ### Jira Connectivity Details and Helper Methods

# COMMAND ----------

# MAGIC %pip install JIRA

# COMMAND ----------

# Jira Connection variables
from jira import JIRA
import json, re
host = "https://databricks.atlassian.net/"
uid = "david.wells@databricks.com"
pswd = dbutils.secrets.get(scope = "DavidW", key = "jira")

### Method to pull CVE data from ticket description details.
cve_pattern = r'CVE-\d{4}-\d{4,7}'
usn_pattern = r'USN-\d{3,5}-\d+'
rhel_pattern = r'RHSA-\d{4}:\d+'
centos_pattern = r'CESA-\d{4}:\d+'
def extract_cves(description):
  objects = []
#  if description: 
  cves = re.findall(cve_pattern, description)
  if cves:
    objects.extend(list(dict.fromkeys(cves)))
  usns = re.findall(usn_pattern, description)
  if usns: 
    objects.extend(list(dict.fromkeys(usns)))
  rhels = re.findall(rhel_pattern, description)
  if rhels: 
    objects.extend(list(dict.fromkeys(rhels)))
  centos = re.findall(centos_pattern, description)
  if centos: 
    objects.extend(list(dict.fromkeys(centos)))
  return objects


# COMMAND ----------

# MAGIC %md
# MAGIC ### Creates the connection object for Databrick's Jira environment

# COMMAND ----------

jira = JIRA(server=host, basic_auth=(uid, pswd), options = { 'rest_api_version': 2, 'headers': { 'Content-Type': 'application/json',  },})
# issues=jira.search_issues('project = patch AND ("AssetID[Short text]" ~ Control_Plane_Host OR "AssetID[Short text]" ~ Data_Plane_Host)',
#            startAt=0, maxResults=100)

# COMMAND ----------

# MAGIC %md
# MAGIC ### Search Jira for Infrastructure Vulnerability Tickets

# COMMAND ----------

maxResults = 100
issues=[]
startAt = 0
last_return = maxResults
while last_return == maxResults:
  ## Pull Jira for infrastructure vulnerability tickets
  # cur = jira.search_issues('project = patch AND ("AssetID[Short text]" ~ Control_Plane_Host OR "AssetID[Short text]" ~ Data_Plane_Host OR "AssetID[Short text]" ~ DBR)', json_result=True, startAt=startAt, maxResults=maxResults)
  #cur = jira.search_issues('project = patch AND ("AssetID[Short text]" ~ Control_Plane_Host OR "AssetID[Short text]" ~ Data_Plane_Host)', startAt=startAt, maxResults=maxResults)
  cur = jira.search_issues('project = patch AND ("AssetID[Short text]" ~ Data_Plane_Host)', startAt=startAt, maxResults=maxResults)
  last_return = len(cur)
  issues.extend(cur)
  startAt += last_return

# COMMAND ----------

# MAGIC %md
# MAGIC ### Save Jira Infrastructure Vulnerability Ticket Details to an objects[] Array

# COMMAND ----------

objects = []
for issue in issues:
  duedate = issue.fields.customfield_14696
  if not duedate or duedate==None:
    duedate = "Unknown"
  
  #for field_name in issue.raw['fields']:
    #print("Field:", field_name, "Value:", issue.raw['fields'][field_name])
  infraCVEs = []
  if issue.fields.description:
    infraCVEs = extract_cves(issue.fields.description)
  
  # In rare cases a ticket can be closed (or status Done) because the CVE isn't relevant to a specific AMI
  # but opened in _another_ ticket with an open status. Working with KP (pavan.kolachoor@databricks.com) the
  # best way to consider a CVE opened or closed is if it is open in ANY ticket then consider it opened. 
  # This variable is a numeric status so that we can determine the open status through a max(status_val) query
  statusVal = 0
  if issue.fields.status.name.lower() == "done":
      statusVal = 0
  elif issue.fields.status.name.lower() == "exception approved":
      statusVal = 1
  else:
      statusVal = 4
    # case "backlog": In progress of being assessed
    # case "blocked": Enginnering investigating the solution
    # case "needs Deployment": Patch available but needs to be deployed
    # case "request Exception": An exception has been requested but not approved
    # case _: All other statuses are considered still open (set to default 0)
  
  if len(infraCVEs)>0:
    severity_val = 0

    #Identify the severity of the vulnerability and map it to an integer value
    #print(issue.fields.customfield_14692.value)
    if issue.fields.customfield_14692.value.lower() == "critical":
      severity_val = 4
    elif issue.fields.customfield_14692.value.lower() == "high":
      severity_val = 3
    elif issue.fields.customfield_14692.value.lower() == "medium":
      severity_val = 2
    elif issue.fields.customfield_14692.value.lower() == "low":
      severity_val = 1
    else: #Informational
      severity_val = 0
    
    label = issue.key
    if issue.fields.customfield_15332 and issue.fields.customfield_15332!="" and issue.fields.customfield_14698 and issue.fields.customfield_14698 != "":
      cloud = issue.fields.customfield_14698
      deployment_type = issue.fields.customfield_15332
      # screw PVC? -veuve
      # if deployment_type = "PVC":
      #   continue
      if deployment_type == "MULTI-TENANT":
        label = "AWS/Azure Multi-Tenant"
      elif cloud == "AZURE":
        label = "Azure " + deployment_type
      else:
        label = cloud + " " + deployment_type

    objects.append({
      "id": issue.key,
      "created": issue.fields.created,
      "updated": issue.fields.updated,
      "due_date": duedate,
      "status": issue.fields.status.name,
      "status_val": statusVal,
      "severity": issue.fields.customfield_14692.value,
      "severity_val": severity_val,
      "asset_id": issue.fields.customfield_14687,
      #"platform": issue.fields.customfield_10009,
      "summary": issue.fields.summary,
      "cves": infraCVEs,
      "status_change_date": issue.fields.statuscategorychangedate
    })
  #   print (f'{issue.key}, {issue.fields.created}, {issue.fields.summary}, {issue.fields.updated}, {issue.fields.updated}, {issue.fields.customfield_14687}, {issue.fields.status.name}')

# COMMAND ----------

# MAGIC %md
# MAGIC ### Search Jira for Data Plane Container Vulnerability Tickets

# COMMAND ----------

## Note: This should have been integrated into the above search, but it was not returning results, so I split the searches. 
## https://i.imgur.com/vN5jG9r.gif?noredirect

DBRmaxResults = 100  
DBRissues=[]
DBRstartAt = 0
DBRlast_return = DBRmaxResults
while DBRlast_return == DBRmaxResults: 
  #cur = jira.search_issues('project = patch AND ("AssetID[Short text]" ~ Control_Plane_Host OR "AssetID[Short text]" ~ Data_Plane_Host OR "AssetID[Short text]" ~ DBR)', json_result=True, startAt=startAt, maxResults=maxResults)
  cur = jira.search_issues('project = patch AND "AssetID[Short text]" ~ DBR', startAt=DBRstartAt, maxResults=DBRmaxResults)
  DBRlast_return = len(cur)
  DBRissues.extend(cur)
  DBRstartAt += DBRlast_return

# COMMAND ----------

# MAGIC %md
# MAGIC ### Save Jira Data Plane Contianer Vulnerability Ticket Details to an objects[] Array

# COMMAND ----------

import re

DBRobjects = []

# def dump(obj):
#  for attr in dir(obj):
#  print("obj.%s = %r" % (attr, getattr(obj, attr)))
# dump(DBRissues)

printone = False;
for issue in DBRissues:
  duedate = issue.fields.customfield_14696
  if not duedate or duedate==None:
    duedate = "Unknown"
  
  if printone:
    for field_name in issue.raw['fields']:
      print("Field:", field_name, "Value:", issue.raw['fields'][field_name])
      printone = False;
  
  DBRcves = []
  if issue.fields.description:
    DBRcves = extract_cves(issue.fields.description)
    
  DBRVersions = []
  for label in issue.fields.labels:
    rex = re.match("dbr\-([^\-]+)", label)
    if rex:
      DBRVersions.append(rex.group(1))
  DBRVersions = list(dict.fromkeys(DBRVersions))
  
  # In rare cases a ticket can be closed (or status Done) because the CVE isn't relevant to a specific AMI
  # but opened in _another_ ticket with an open status. Working with KP (pavan.kolachoor@databricks.com) the
  # best way to consider a CVE opened or closed is if it is open in ANY ticket then consider it opened. 
  # This variable is a numeric status so that we can determine the open status through a max(status_val) query
  statusVal = 0
  if issue.fields.status.name.lower() == "done":
      statusVal = 0
  elif issue.fields.status.name.lower() == "exception approved":
      statusVal = 1
  else:
      statusVal = 4
    # case "backlog": In progress of being assessed
    # case "blocked": Enginnering investigating the solution
    # case "needs Deployment": Patch available but needs to be deployed
    # case "request Exception": An exception has been requested but not approved
    # case _: All other statuses are considered still open (set to default 0)
  
  if len(DBRcves)>0:
    #Identify the severity of the vulnerability and map it to an integer value
    #print(issue.fields.customfield_14692.value)
    if issue.fields.customfield_14692.value.lower() == "critical":
      severity_val = 4
    elif issue.fields.customfield_14692.value.lower() == "high":
      severity_val = 3
    elif issue.fields.customfield_14692.value.lower() == "medium":
      severity_val = 2
    elif issue.fields.customfield_14692.value.lower() == "low":
      severity_val = 1
    else: #Informational
      severity_val = 0
    
    DBRobjects.append({
      "id": issue.key,
      "created": issue.fields.created,
      "updated": issue.fields.updated,
      "due_date": duedate,
      "status": issue.fields.status.name,
      "status_val": statusVal,
      "severity": issue.fields.customfield_14692.value,
      "severity_val": severity_val,
      "asset_id": issue.fields.customfield_14687,
      #"dbr_version": issue.fields.labels,
      "dbr_versions": DBRVersions,
      "summary": issue.fields.summary,
      "cves": DBRcves,
      "status_change_date": issue.fields.statuscategorychangedate
    })

# COMMAND ----------

# MAGIC %md
# MAGIC ### Save Vulnerability Objects to the daily Vulnerability files

# COMMAND ----------

#Infrastructure (e.g., control plane, ) Layer CVEs:
myJson = sc.parallelize(objects)
myDf = sqlContext.read.json(myJson)
spark.sql("DROP TABLE IF EXISTS Vulnerability.InfrastructureCVEs")
myDf.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable("Vulnerability.InfrastructureCVEs") #Overwrite the whole table since we're pulling all Jira tickets
#myDf.write.format("delta").mode("overwrite").option("mergeSchema", "true").save("/Users/david.wells@databricks.com/vuln_mgmt/list_of_patch_tickets")
#display(myDf)

#DBR (e.g., containers) Layer CVEs
DBRmyJson = sc.parallelize(DBRobjects)
DBRmyDf = sqlContext.read.json(DBRmyJson)
spark.sql("DROP TABLE IF EXISTS Vulnerability.DBRCVEs")
DBRmyDf.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable("Vulnerability.DBRCVEs") #Overwrite the whole table since we're pulling all Jira tickets
#DBRmyDf.write.format("delta").mode("overwrite").option("mergeSchema", "true").save("/Users/david.wells@databricks.com/vuln_mgmt/list_of_DBR_patch_tickets")
#display(DBRmyDf)
